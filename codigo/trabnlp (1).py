# -*- coding: utf-8 -*-
"""TrabNLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BVJBnOaMnvFfUlTdDEU93VEOnIad6sxN
"""



# Commented out IPython magic to ensure Python compatibility.
import nltk
import pandas as pd
import os
import numpy as np
import string
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
import matplotlib.cm as cm
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

"""# Conectar no Google Drive para carregar arquivo"""

from google.colab import drive
drive.mount('/drive')

import os
workdir_path = '/drive/My Drive/'
os.chdir(workdir_path)

"""# Carrengando arquivo e verificando Nulos"""

data = pd.read_csv('reclamacoes2.txt',encoding='windows-1252',sep =';')
data['serviço'].tail
#data['serviço'].isnull().sum()

"""# Criando dataframe Pandas com a coluna de trabalho"""

data_serv = pd.DataFrame()
data_serv['servico'] = data['serviço']

"""# Convertendo caracteres para minúsculo"""

import re

to_lower = lambda x: x.lower()
data_serv['servico2'] = data_serv.servico.map(to_lower)

data_serv['servico2'].head()

"""# Realizando Tokenização"""

import nltk 
nltk.download('punkt')
from nltk.tokenize import word_tokenize

data_serv['tokens'] = data_serv.servico2.map(word_tokenize)

data_serv.head()

"""# Retirando StopWords e expressões baseada em dicionário gerado"""

from nltk.corpus import stopwords
nltk.download("stopwords")

stop_words = stopwords.words('portuguese')

dicionario = {'(',')','/',' ',' ,','.','etc',',',' '}

parser = lambda x: [y for y in x if y not in stop_words and y not in dicionario]
data_serv['tokens2'] = data_serv.tokens.apply(parser)

data_serv.head()

"""# Realizando STEM nos tokens -> Sem necessidade - Retirar esta célula"""

from nltk.stem import SnowballStemmer

dic_stem = SnowballStemmer('portuguese')

stem_tokens = lambda x: [dic_stem.stem(y) for y in x]
data_serv['tokens3'] = data_serv.tokens2.apply(stem_tokens)
data_serv.head()

"""# Compondo texto para a WordCloud"""

#data_serv['tokens2'].isnull().sum()
lista = sum(data_serv['tokens2'].tolist(),[])
lista2 = " ".join([text for text in lista])

"""# Gerando WordCloud"""

wordcloud_serv = WordCloud(collocations=False, background_color = "white", max_words = 50).generate(lista2)

plt.figure(figsize = (40,30),
           facecolor = 'k',
           edgecolor = 'k')
plt.imshow(wordcloud_serv, interpolation='bilinear')
plt.axis('off')
plt.tight_layout(pad=0)
plt.savefig("Servicos_wordcloud.png")
plt.show()